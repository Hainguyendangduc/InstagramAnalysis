# -*- coding: utf-8 -*-
"""Data-mining-insta

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1flcDTma1BnNn4wTOiRd7E8yio4crg776
"""

import pandas as pd
import re

import re

from google.colab import drive
drive.mount('/content/drive')

df1 = pd.read_json('/content/drive/MyDrive/data/result1-4041.json')
df2 = pd.read_json('/content/drive/MyDrive/data/result2-7713.json')
df3 = pd.read_json('/content/drive/MyDrive/data/result3-10000.json')
df4 = pd.read_json('/content/drive/MyDrive/data/6936.json')
df5 = pd.read_json('/content/drive/MyDrive/data/7338post.json')

df = pd.concat([df1, df2, df3, df4, df5])

df.drop_duplicates(subset=['url'], keep='first', inplace=True)
df.drop_duplicates(subset=['caption'], keep='first', inplace=True)
df.drop_duplicates(subset=['shortCode'], keep='first', inplace=True)

df.drop_duplicates(subset=['caption'], keep='first', inplace=True)

len(df)

"""## Tiền xử lý dữ liệu"""

def clean_text1(caption): #remove character
  result = str(caption).lower()
  result = re.sub(r'[^\x00-\x7F]+', ' ', result)
  icon_pattern = r'[^\w\s]' #remove icon
  result = re.sub(icon_pattern, ' ', result)
  result = result.replace(' a ',' ') #remove article
  result = result.replace(' an ',' ')
  result = result.replace(' the ',' ')
  result = result.replace(' am ',' ') #remove verb tobe
  result = result.replace(' is ',' ')
  result = result.replace(' are ',' ')
  result = result.replace(' as ',' ')
  result = result.replace(' rather ',' ')
  result = result.replace(' so ',' ')
  result = result.replace(' too ',' ')
  result = result.replace(' on ',' ')
  result = result.replace(' in ',' ')
  result = result.replace(' at ',' ')
  result = result.replace(' to ',' ')
  result = result.replace(' of ',' ')
  result = result.replace(' and ',' ')
  return(result)

!pip install nltk

import nltk
from nltk.corpus import words

nltk.download('words')

def clean_text2(text): #check word in English
    english_words = set(words.words())
    words_in_text = text.split()

    for word in words_in_text:
        if word not in english_words:
          text = text.replace(word, "")

    return text

def clean_text3(caption): #remove " "
  result = str(caption)
  result = result.replace('   ',' ')
  result = result.replace('  ',' ')
  result = result.replace('   ',' ')
  result = result.replace('.',' ')
  result = result.replace(',',' ')
  return(result)

def clean_text4(caption):
  result = str(caption)
  split = result.split(" ")
  cleaned_text = [word for word in split if len(word) > 1 ]
  cleaned_text = " ".join(cleaned_text)
  return(cleaned_text)

df['caption'] = df['caption'].apply(clean_text1)

df['caption'] = df['caption'].apply(clean_text2)

df['caption'] = df['caption'].apply(clean_text3)

df['caption'] = df['caption'].apply(clean_text4)

df = df[df['caption'] != ""]

df

len(df)

df['caption'].iloc[27175]

#df.to_csv('covid_caption_after1.csv', index=True)

df['caption'].iloc[0]

def clean_text(caption):
  result = str(caption)
  result = result = result.replace('\n',' ')
  return result

df['caption'] = df['caption'].apply(clean_text)

df['caption'] = df['caption'].apply(clean_text3)

df['caption'].iloc[0]

df['year'] = df['timestamp'].dt.year

for i in df.columns:
  print(i)

df.to_csv('caption_after.csv', index=False)

new_columns = ['shortCode','year', 'caption', 'hashtags']
df1 = df[new_columns]

df1

len(df1)

df1.to_csv('caption.csv', index=False)